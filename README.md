# Machine-Learning-Engineer-Interview

Machine-Learning-Engineer-Interview 질문 정리

## 확률과 통계
- 선험적 확률과 경험적 확률

- 기댓값, 분산, 공분산, 상관계수, 공분산 행렬

- 확률변수, 확률 분포, 확률 밀도 함수, 누적 분포 함수, 확률 질량 함수, 누적 질량 함수

- 이항 분포

- 기하 분포

- 포아송 분포

- 지수 분포

- 중심극한정리

- 카이 제곱 분포

- 모집단, 모수, 표본, 표준 오차

- 검정 통계량

- t-value (두 개의 표본을 비교할 때 사용 - 평균을 활용)

- F-value (여러 개의 표본을 비교할 때 사용 - 분산을 활용)

- 귀무가설과 대립가설

- 감마 분포
    - https://m.blog.naver.com/mykepzzang/220842759639

- 베타 분포
    - https://m.blog.naver.com/mykepzzang/220843077734

- confusion matrix

- 귀무가설과 대립가설

- p-value의 의미

- 신뢰 구간의 의미

- 1종 오류와 2종 오류

- 평균과 중앙값

- 표본과 표준 오차

- 빈도주의 VS 베이지안

- Maximum Likelihood Estimation

- Maximum A Posterior

- KL-Divergence

- Entorpy외 정보 이론

- Bayes Rule

- 모수적 방법론과 비모수적 방법론

- A/B Test

- 중심극한정리

- 통계학이란

- 심슨의 역설

## 선형대수학
- 선형성과 비선형성
    - 그러면 왜 딥러닝은 비선형변환을 강조하는 것일까?? 이 부분에 대해서 생각해보면 딥러닝 자체가 행렬과 행렬의 곱이기 때문에 여기 까지는 선형 변환이라고 할 수 있다. 근데 인풋 행렬로 표현된 아웃풋이 활성화 함수에 의하여 값의 변형이 일어니기 때문에 서로 다른 인풋이 동일한 아웃풋을 생성할 수도 있기 때문에 비선형 변환이라고 표현하는 것 같다.

- 고윳값과 고유벡터

- PCA

- 선형변환

- 코사인 유사도

- 퓨리에 변환

## Machine Learning

## Deep Learning
- 빈도주의 관점의 딥러닝

- 베이지안 관점의 딥러닝

- Representation Learning

- 데이터 불균형에 대응 하는 방법

## NLP
- TF-IDF

- Word2Vec

- 언어 모델

- N-gram 언어 모델

## RecSys
- Multi-Armed Bandit

- Cold-start-Problem
    - content-based Model, 초기 유저 정보 수집

## Python
- global interpreter lock

- Flask의 장점과 단점

- Flask에서 WSGI가 무엇인지

- 깊은 복사와 얕은 복사 (list와 엮어서)

- global과 nonlocal

- set 동작 구조

- dict 동작 구조 (key에 list나 tuple을 쓸 수 있는가)

## CS

- 배열

- 연결리스트

- 스택

- 큐

- 덱(deque)

## MLOps
- ML-System-design-pattern

- Docker

## Project

## 인성 및 공통
