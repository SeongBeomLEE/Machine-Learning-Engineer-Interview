# 확률과 통계
## 통계학이란
- 통계학이란 한 마디로 표현하면, 모집단의 특성을 잘 대표하는 표본을 뽑아서 그 표본에 있는 제한된 정보를 이용하여 미지의 값인 모집단의 특성인 모수들에 대하여 통계적 추론을 하고자 하는 학문

## 선험적 확률과 경험적 확률
- 선험적 확률은 각 사건이 발생하는 확률이 같다는 것으로, 시행에 대해서 일어날 수 있는 모든 경우의 수가 N가지이고, 어떤 사건이 일어나는 경우의 수가 K가지일 떼, 어떤 사건이 일어나는 확률이 K/N인 것을 뜻함, 결국은 수학적으로 계산 가능한 확률을 의미함(주사위 같은)

- 경험적 확률은 같은 시행을 여러 번 반복하여 얻을 수 있는 횟수를 통해 나오는 확률을 의미함, 즉 시물레이션이나 실험을 통해서 나오는 확률임, 이런 확률이 필요한 이유는 수학적 확률 처럼 모든 사건이 발생할 확률이 같지 않을 수도 있기 때문임

## 기댓값, 분산, 공분산, 상관계수, 공분산 행렬
- 기댓값은 확률적 사건에 대한 평균 값으로, 사건이 일어나서 얻는 값과 그 사건이 일어날 확률을 곱한 것을 모든 사건에 대해 합한 값으로, 어떤 확률적 사건에 대한 퍙균의 의미를 갖음

- 분산은 데이터가 평균으로 부터 얼마나 퍼져있는지를 가늠할 수 있는 값으로, 데이터의 분포를 알 수 있음

- 분산은 우리가 한 예측이 얼마나 불확실한지의 정도의 표현으로도 사용 가능함, 왜냐하면 분산이 작다는 것은 분포의 폭이 작다는 것이고, 분산이 크다는 것은 분포의 폭이 넓다는 것임 분포의 폭이 넓을 수록 우리가 예측하고자 하는 값의 불확실성은 높아진다고 볼 수 있음

- 공분산은 두 변수 간의 상관 관계를 파악하는데 쓰이는 개념으로, 각 변수의 편차를 서로 곱한 것의 평균 이다.

- 그런데 공분산 자체가 X와 Y의 단위의 크기에 영향을 받기 때문에, 이를 보완하고자 공분산을 표준편차로 니누어 표준화 한 것이 상관 계수이다.

- 공분산 행렬은 여러 개의 변수가 서로 어떤 관계를 가지는지 나타내고자, 공분산을 행렬로 구한 것이 바로 공분산 행렬이다.(대각 행렬은 분산, 나머지 부분은 각 변수 간의 공분산 값임)

## 확률 변수, 확률 분포, 확률 밀도 함수, 누적 분포 함수, 확률 질량 함수, 누적 질량 함수
- 확률 변수는 표본 공간게 있는 샘플을 각각 하나의 실수 값으로 변환해주는 함수 식

- 확률 변수는 어떤 확률 공간에서 확률 값을 나타내는 특정 값이 될 수 있는 변수를 의미함

- 획률 분포는 샘플(관측치)들이 가질 수 있는 수치 값을 각각 0과 1 사이의 확률로 표현할 때 이 확률 값들의 패턴

- 확률 분포는 확률 변수가 특정한 확률 값을 가지는 대응 관계를 의미함(이산확률분포, 연속확률분포)

- 모든 확률 분포는 한 개 이상의 모수를 가지고 있으며, 이는 확률 분포의 모양을 결정함(정규 분포의 경우 평균과 분산 2개의 모수가 있고 이들이 정규 분포의 모양을 결정)

- 많은 경우 분포의 모수는 알려져 있지 않으며 모수를 추측해보는 과정을 통계학에서 추정이라고 함

- 확률 함수는 샘플이 가질 수 있는 값들을 확률로 표현하기 위해서 쓰이는 대응 함수

- 확률 밀도 함수(PDF)는 연속 확률 변수의 분포(확률)를 나타내는 함수

- 누적 분포 함수(CDF)는 연속형 분포의 주어진 확률 변수가 특정 값보다 작거나 같은 확률을 나타내는 함수

- 확률 질량 함수(PMF)는 이산 확률 변수의 분포(확률)를 나타내는 함수

- 누적 질량 함수(CMF)는 이산형 분포의 주어진 확률 변수가 특정 값보다 작거나 같은 확률을 나타내는 함수

## 모수적 모델, 비모수적 모델
- 모수적 모델은 알려진 확률분포를 기반으로 해당 파라미터를 추정하는 과정이 포함되어 있는 모델(예를 들어 선형 모델을 모델 구축 시에 정규 분포를 가정하기 때문에 모수적 방법론임)

- 비모수적 모델은 확률 분포를 가정하지 않고, 하이퍼파라미터를 이용해 값을 추정하는 모델

- 위 두가지 관점에서 보면 DNN은 파라미터와 하이퍼파리미터 두 개를 모두 가지고 있기 때문에, 모수적과 비모수적 모델의 특징을 모두 가진다고 볼 수 있음(그런데 딥러닝이 특정 확률 분포를 가정하고 모델을 학습시키는 것은 아님)

- 모수적 모델과 비모수적 모델은 데이터의 양이나 분포에 의존하지 않고 일정 개수의 모수로 모델이 표현되는가로 구분할 수도 있음(딥러닝과 선형회귀 같은 모델은 데이터의 양이나 분포에 의존하나, k-NN과 의사결정 나무는 데이터의 양이나 분포에 의존하지 않고 단순히 하이퍼파라미터에 의존함) 

## 이항 분포
- 이항 분포는 동전 던지기의 앞면 혹은 뒷면과 같이 두 가지 사건만 일어날 수 있는 경우에 대해 기대해 볼 수 있는 분포

- 이항 분포는 특정 조건을 만족하면 가 분포가 정규 분포에 근사하기 때문에 정규 분포를 이해할 수 있게 해주는 좋은 징검다리 역할을 수행

- 이항 분포는 연속된 n번 독립적 시행에서 각 시행이 확률 p를 가질 때의 이산 확률 분포

- 이항분포의 확률질량함수의 식은 아래와 같음, 식의 의미는 성공 확률 p를 갖는 이벤트를 n번의 시행 했는데, 그 중 성공한 횟수는 k번 이라는 것임, 그러면 자연스럽게 1-p의 시행 횟수는 n-k가 됨

- $ \binom n k p^k(1-p)^{n-k} $

- 이항분포는 p라는 획률을 가지는 사건을 연속 n회 시행했을 때, 0~n회 사이의 시행 중 우리가 원하는 사건이 몇번 발생할 지를 확률적으로 기술해놓은 분포라고 할 수 있음

- 총 시행 횟수가 n, 성공 확률이 p인 이항 분포의 평균 값은 np, 분산은 np(1-p)

- 수학자들은 이항 분포가 정규분포의 형태와 유사해질수 있다고 볼 수 있는 기준을 np와 $\sqrt{np(1-p)}$가 5보다 클때로 보며, 이때 평균이 np이고 분산이 np(1-p)인 정규분포를 따른다고 함

## 기하 분포
- 기하 분포는 성공 혹은 실패의 두 가지 경우의 수로 구성된 시행을 연달아 수행 시 처음 성공할 때 까지 시도한 횟수 k에 대한 분포

- 성공 확률이 p인 시행에 대해 k번 시행 후 첫번째 성공을 얻을 확률은 다음과 같으며, 식을 보면 (1-p)를 매 항마다 계속해서 곱해나간다는 것을 알 수 있음(계속 틀렸으니깐 당연한거임)

- $(1-p)^{k-1}p$

- 기하 분포에서 보여주는 것은 성공 확률이 p일 때 k번째 처음으로 성공할 수 있는 확률을 의미함
    
- 분포의 모양을 바탕으로 현재 내가 하고 있는 일이 언제 쯤에 성공할 지 대략적인 감을 알 수 있음, 즉 성공 확률이 높은 행동일 수록 초기에 매우 큰 값을 가지고, 그 뒤에 제일 처음으로 성공할 확률이 낮아지지 점점 급감할 것임, 반대로 성공 확률이 낮은 행동은 언제 성공할지 누구도 모르니 전체적으로 평탄한 모양을 기질 것임

- 합격 확률이 0.2인 시험이 있을 때, 이 시험을 3번째 만에 합격할 확률은?
    - 0.2 + (0.8)^1*0.2 + (0.8)^2*0.2 = 0.448
    - 1, 2, 3번째에 성공할 확률들을 다 구해서 더하면 됨


## 포아송 분포
- 정해진 시간 안에 어떤 사건이 일어날 횟수에 대한 기댓값을 $\lambda$ 라고 했을 때, 그 사건이 n회 일어날 확률은 다음과 같음

- $f(n;\lambda) = \frac{\lambda^n e^{-\lambda}}{n!}$

- 이항분포에서 n이 너무 크고 p가 너무 작은 경우에 이항 분포의 확률분포를 근사적으로 계산하기 위해서는 극한값을 이용한 새로운 형태의 분포를 제시하는 것이 바람직하고, 이 새로운 형태의 분포가 바로 포아송 분포

- 포아송 분포는 수 많은 사건 중(n->무한) 특정한 사선이 발생할 확률이 매우 적은(즉, p -> 0)확률 변수가 갖는 분포

## 지수 분포
- 사건이 서로 독립적일 때, 일정 시간동안 발생하는 사건의 횟수가 포아송 분포를 따른다면, 다음 사건이 일어날 때 까지의 대기 시간은 지수 분포를 따름

- 포아송 분포는 단위 시간동안 어떤 사건이 평균적으로 $\lambda$ 회 발생한다고 했을 때, 단위시간동안 사건이 k번 일어날 확률에 대한 분포를 지칭

- 그러면 여기서 다음 사건이 처음 일어나는 때 까지 걸리는 시간에 대한 분포를 구할 때는 지수 분포를 사용

## 정규 분포
- 어떤 값을 중심으로 대칭적으로 분포하며 중심에서 멀어질수록 도수가 작아지는 종 모양의 분포

## 중심극한정리
- 모집단의 분포의 모양에 상관 없이 표본 평균의 평균은 정규 분포를 따른 다는 정의로 해당 정의를 이용해 모집단의 모수인 평균을 통계적으로 추론할 수 있고, 모집단의 평균을 알면 모집단의 특성을 추론할 수 있기 때문에 중요한 정의입니다.

- 여기서 또 신기한 점은 표본을 추출하는 모집단의 서로 독립적이라면, 여러개의 서로 다른 모집단에서 표본을 뽑더라도 표본 평균의 평균은 정균 분포를 따르게 됩니다. (랴푸노프 중심극한정리)

- 그리고 저희 대체적으로 표본을 비교할 때 평균을 많이 사용하기 때문에, 중심극한정리를 염구해두고 만든 많은 이론들이 있어서 본 정의가 중요합니다.

## 카이제곱분포
- 표준정균분포를 따르는 확률 변수들을 k개 샘플링하고, 그 값들 제곱합하여 히스트그램으로 나타낸 분포

- 카이제곱분포 또한 중심극한정리에 의해서 k의 수가 커지면 정균분포를 따르게 됨

- 카이제곱 분포는 오차(error) 혹은 편차(deviation)를 분석할 때 도움을 받을 수 있는 분포이기 때문에 사용됨

- 여기서 중요한 점은 우리가 보통 error를 정규분포로 설계한다는 점을 이해해야함(회귀 분석의 가정인 정규성)

- 적합도 검정은 독립변수가 하나이고 이론적으로 기대되는 빈도의 분포(frequency distribution)와 관찰한 빈도의 분포를 비교하기 위해 사용

- 교차 분석은 범주형 변수가 여러 개인 경우에 적용하는 분석 방법, 교차 분석의 목적은 여러 범주형 변수의 범주 간 차이가 기댓값에서 유의하게 벗어나는지 확인하는 것

## 모집단, 모수, 표본, 표준 오차
- 모집단은 정보를 얻고자 하는 관심 대상의 전체 집합을 의미

- 모수는 모집단의 특성을 의미, 우리는 전체 집단의 모든 데이터를 알지 못한더라도 수학적으로 그 분포를 기술할 수 있는 특성값을 알 수만 있다면, 비슷하게 모집단의 특성을 통계적으로 확인할 수 있는데, 여기서 특성치들을 우리는 모수라고하며, 모집단의 특성을 나타내는 모수를 파악하여 모집단의 특성을 파악하고자하는 것이 목표

- 표본이란 모집단의 부분집합을 의미

- 표본을 추출하는 이유는, 유리가 모집단 전체에 대해 검서하기에는 비용이 너무 많이 들기 때문임(현실적으로 모집단을 모두 조사하는 것은 불가능함)

- 표본은 매번 추출할 때 마다 그 값이 달라지는 특성을 가지며, 표본으로부터 그 분포의 특성을 나타내는 표본 통계량을 만들 수 있고, 표본 통계량은 모수의 추정치로 볼 수 있으며, 이 값은 항상 오차를 수반함

- 표준 오차란 표본 통계량의 표준 편차를 의미함(여러 개의 표본을 얻어서 거기서 표본 통계량을 얻으면, 그 표본 통계량 값들의 표준 편차를 구할 수 있고, 그 값을 표준 오차라고 함)

- 표준 편차는 모집단의 분포가 얼마나 퍼져있는가를 서술하는 개념이고, 표준 오차는 표본 통계량(추정치)의 평균 값들에 대한 불확실도를 수치화한 개념

## 검정 통계량
- 검정 통계량은 통계적 가설의 진위 여부를 검정하기 위해 표본으로 부터 계산하는 통계량

- 즉, 검정 통계량은 표본 통계량을 2차 가공한 형태로 생각하면 편함, 통계적 가설 진위 여부를 검정한다는 것은 검정통게량의 값이 기준을 벗어나는지 확인하여 세워둔 가설이 틀렸다고 할 수 있는지 확인하는 과정임

## t-value
- 우리가 두 표본 집단간의 평균 차이를 비교한다고 할 때, 우리가 비교하고자하는 평균 값은 표도 평균이기 때문에 오차를 염듀하여 두 표본 간의 차이에 관한 지표를 만드렁야 한다. 우리는 표돈 통계량의 불확실성에 대한 값인 표준 오차라는 것을 알고 있다. 따라서 t-value는 표본 평균과 표준 오차, 즉 불확실성을 가지고 계산할 수 있다.

- 두 표본 그룹 간의 평균 차이 / 두 그룹간 평균 차이에 대한 불확실도로 t-value를 계산할 수 있으며, 두 그룹간 평균 차이에 대한 불확실도는 각 표본의 분산 값을 각 표본의 개수 n으로 나누어 합한 후 루트를 취한 값으로 계산됨

- t-value들의 분포를 계산하여 공식화 한 것이 t-분포라고 할 수 있음

- t-value는 평균의 차이에 평균의 차이에 대한 표준오차를 나눠준 값으로 정의

## F-value
- F-value는 여러 표본 집단을 비교하기 위한 지표이며, t-value와 마찬가지로 그룹 간의 차이 / 불확실도로 계산할 수 있음, 근데 T-value와 달리 계산 시에 분산을 사용함

- t-value를 제곱한 값이 결국엔 F-value임

- 내용 더 추가하기

## 귀무가설과 대립가설
- 귀무가설은 "새로울 게 없다는 가설"

- 대립가설은 "새로운 것이 있다는 가설"

- 실험을 통해서 새로운 사실을 발견했다는 사실을 입증하기 위해서 귀무가설을 사용하는 이유
    - 참이 아님을 증명하는 것이 참임을 증명하는 것보다 휠씬 쉽기 때문에
    - 귀무가설을 "올바르게" 서술하는 것이 대립가설을 "정확하게" 서술하는 것보다 실패할 가능성이 적음
    - 우리는 모수에 대해서 알 수 없으며, 연구에 있어 주관성이 개입되어선 안되기 때문에

- 위와 같은 이유로 귀무가설을 검증하는데 실패함으로써 간접적으로 새로운 가설, 즉 대립가설에 대해 확인하고자 하는 것

- 즉, 실험에 어떤 변화가 있다는 사실을 검증하고자 한다면 역으로 가설이 없다고 가정한 뒤에 실험을 진행하는 것임(귀무 가설 설정)

- 변화가 없다는 가설(귀무가설)에 모순이 있다는 것을 발견하게 되면 이것을 근거로 변화가 있다는 사실(대립가설)을 간접적으로 증명할 수 있게 되는 것임

- 귀무가설을 이용한 검증 방법은 무죄 추정의 원칙으로 설명할 수 있음, 무죄 추정 원칙을 따르면 용의자나 피고인은 유죄로 판결이 확정(귀무가설이 기각된 상태)되기 전 까지는 무죄로 추정(귀무가설이 기각되지 않은 상태)하고, 유죄로 판결하기 위해선 피고인이 실제로 무죄라고 가정했을 때 발생할 수 없는 증거나 상황(통계학적으로 유의한 수준)이 뒷받침 되어야 함

- 귀무가설 검증 과정은 오로지 검증 실패에만 주안점을 두는 과정이기 때문에, 귀무가설을 기각할 수 있게 되었다고 해서 대립가설을 증명한 것은 아니라는 점이 중요함

- 대립가설을 간접적으로 이용한 통계적 추론 방법이 신뢰 구간을 이용한 검정 방법
- 대립가설을 직접적으로 아용항 통계적 추론 방법이 베이즈 추론 방법

## p-value
- p-value는 이 검정 통계량에 관한 확률인데, 우리가 얻은 검정 통계량보다 크거나 같은 값을 얻을 수 있을 확률을 의미(즉 p-value가 0.05 보다 작다는 것은 현재 실험하고자 하는 집단들은 서로 다른 특성을 가지고 있다는 것을 의미함, 왜? p-value는 확률 값이니깐 낮은 값이 나오면 현재 값이 나올 확률 자체가 낮다는 것임)

- 우리가 계산하는 검정 통계량들은 거의 대부분이 귀무가설을 가정하고 얻게되는 값이라는 것

- 두 표본 평균의 차이를 검증한다고 할 때, 두 표본 집단의 모집단은 같다는 가정을 전제

- "우리가 얻은 데이터에 있는 두 표본 집단이 같은 모집단에서부터 나온거라고 치자, 그랬을 때, 우리가 이런 검정 통계량(가령, t-value)을 얻었는데 이게 얼마나 말이되는거냐?" 이에 대한 해답이 p-value

- 표본 통계량(표본 집단의 특성) -가공-> 검정 통계량(표본 통계량을 가지고 통계적 가설의 진위 여부를 판단하기 위한 값, t-value / F-value 등) -가공-> p-value(검정 통계량에 관한 확률, 검정 통계량이 유의미한지 판단하기 위한 값)

- p-value는 효과의 크기(effect size)와 표본의 크기(n 수)의 정보를 한꺼번에 담고 있음(검정 통계량을 압축한 정보)

- 효과의 크기가 커지거나 표본의 크기가 커지거나 둘 중 하나만 변하더라도 p-value는 마치 유의한 차이를 담보할수 있을 것 마냥 작아짐, 즉 실제로 한 모집단에서 두 표본 집단이 나왔음에도 효과의 크기나 표본의 크기가 너무 커서 p-value는 0.05보다 낮을 수 있으며 귀무가설이 기각되어 대립 가설이 채택됨에도 불구하고 대립 가설이 참이 아닐 수도 있음

- 귀무가설을 기각할 수 있다는 것은 귀무가설과 현재 얻은 결과가 서로 양립할 수 없음을 의미하며, 우리는 양립할 수 있는 정도를 표현하기 위해서 p-value를 사용

- p-value는 확률값으로써 귀무가설과 현재 얻은 결과가 얼마나 일치(compatible)하는지를 말해주는 값임

- 낮은 p-value (통상 0.05 이하)를 얻었다는 것은 귀무 가설과 현재의 실험 결과가 그만큼 일치하지 않는다는 것을 말하는 것이고, 이에 따라 귀무 가설을 기각함

## 신뢰 구간
- 표본 통계량에는 항상 불확실성은 수반하기 때문에(샘플링), 그나마 내가 확실히 말할 수 있는 정도를 구간으로 표현한 신뢰 구간을 이용해 통계적 추정을 힘

- 즉, 내가 지금 추출한 표본 평균은 모평균으로부터 2 * 표준 오차(SEM, 표본 평균의 표준 편차) 범위 안에 95% 확률로 들어온다라고 설명하는 것

- 여기서 95% 라는 의미는 100번 정도 샘플링을 했을 때, 우리가 표본 평균을 바탕으로 모평균을 추론했을 때, 그 값이 95번 정도는 해당 신뢰 구간안에 들어온다는 의미임

- 여기서 95% 는 신뢰 수준

- 2 * 표준 오차(SEM, 표본 평균의 표준 편차) 범위는 신뢰 구간

- p-value는 효과의 크기가 커지거나 표본의 크기가 커지거나 둘 중 하나만 변하더라도 그 값이 매우 작아질 수 있기 때문에, 효과의 크기(effect size)를 함께 보여주는 신뢰 구간을 이용하면 더 많은 정보들을 확인할 수 있으므로, 두 개의 값을 같이 이용하는 것이 중요함(가령 두 값의 범위가 매우 작다면 아무리 p-value의 값이 낮더라도 실제로는 유의미한 차이를 낸다고 볼 수는 없을 것임)

## 1종 오류와 2종 오류
- 1종 오류는 귀무가설이 참인데 잘못 기각할 때 발생하는 오류

- 2종 오류는 귀무가설이 거짓인데 기각하지 않았을 때 발생하는 오류

- 검정은 확률을 기반으로 하기 때문에 어떤 가설 검정도 100% 확실한 것은 없음, 이에 언제나 잘못된 결론을 내릴 가능성이 있음

- 우리가 사건에 대해 다루는 가설은 딱 두가지이다. 이 사건이 일어났거나, 일어나지 않았거나.

- 통계학이 사건이 일어나지 않았다는 가정에 초점을 더 맞추는 경우가 많기에, 이러한 가정에 이름도 붙여놓았는데, 그것이 바로 “귀무가설”이다.

- 귀무가설은 아무일도 일어나지 않았음을 가정하는 가설

- 1종 오류의 정의는 “귀무가설이 참인데 잘못 판단해 기각 해버리는 오류”

- 귀무가설이 참이라는 말은 아무 일도 일어나지 않았음을 의미(False Alarm
), 즉 실제로는 일이 일어나지 않았는데도 기각(즉, 알람이 울리는 것) 해버린 것

- 2종 오류의 정의는 “귀무가설을 거짓인데도 기각하지 않아서 생기는 오류”

- 귀무가설이 거짓이라는 말은 어떤 일이 실제로 발생했음을 의미(Miss
), 즉 실제로 일어난 일임에도 기각(즉, 알람이 울리는 것)할 타이밍을 놓친 것

- p-value는 “귀무가설이 맞다고 했을 때, 귀무가설이 말이 될 확률”을 의미하기 때문에  p-value는 1종 오류를 범할 확률과 같은 의미를 갖음

## 빈도주의 통계와 베이지안 통계
- 빈도 주의에서 확률은 철저히 객관적인 실험에 의해서 계산된 값을 의미함, 즉 실제 사건을 기반으로 확률을 계산함(확률을 그 값 자체로 보는 것)

- 베이지안은 확률을 사건 발생에 대한 믿음 또는 척도로 바라보는 관점을 의미함, 따라서 실제 발생하지 않은 사건이라도 주변 요인에 대한 확률, 즉 사전 확률만 있다면 다른 사건이 발생할 확률을 계산할 수 있음(확률을 주장에 대한 신뢰도로 보는 것)

- 즉 전국 대학생의 평균 연령을 23살이라고 한다며, 빈도주의 관점에서는 실험을 더이상 하지 않는다면 그 값은 변하지 않음

- 반대로 베이지안에서는 전국 대학생의 평균 연령이 23살일 확률이 높겠지만, 아닐 확률도 존재 한다고 말하며, 그 확률 분포에 대해서 설명함, 이처럼 베이지안 관점은 우리가 구하고자 하는 값을 정확히 구하지 않고, 어떤 값일 확률이 어느 정도인지에 대한 확률 분포로 대답함

- 일반적으로 사용하는 Deep Learning은 빈도주의 관점임, 왜냐하면 Model의 Parameter들이 하나의 값으로 정해져 있고, 그에 따라 output도 하나의 값으로 출력하기 때문에

- 정답 뿐만 아니라 정답이 어느 값일 확률이 높은지에 대한 distribution을 출력하게 된다면 이는 베이지안 관점의 Deep Learning임

## 베이즈 정리
- 베이즈 정리는 새로운 정보를 토대로 어떤 사건이 발생했다는 주장에 대한 신뢰도를 갱신해 나가는 방법

- 베이지안 관점의 통계학에서는 사전 확률과 같은 경험에 기반한 선험적인, 혹은 불확실성을 내포하는 수치를 기반으로 하고, 거기에 추가 정보를 바탕으로 사전확률을 갱신(귀납적 추론 방법)

- 관찰을 통해서 예측하고자 하는 클래스가 주어졌을 때 변수가 발생할 분포인 Likelihood를 구하고(Likelihood 만을 사용하여 클래스를 분류하기 위해서는 예측하고자 하는 클래스가 똑같은 비율로 존재한다는 가정이 필요함), 클래스의 비율에 대한 정보인 사전 확률을 서로 곱하고(클래스가 똑같은 비율로 존재하지 않기 때문에 무엇이 더 희귀한지에 대한 정보가 반영되어 있는 사전 지식임), 구한 사전 확률과 Likelihood를 이용하여 Evidence를 계산하고 이를 분모 취한다. 이렇게 값을 구하게 되면 우리는 해당 변수가 주어졌을때 해당 클래스일 확률인 사후 확률을 알 수 있게 된다. 이 사후 확률을 바탕으로 현재 주어진 위치에서 제일 높은 확률 값을 가진 클래스로 우리는 예측을 하게 된다.

- 변수들에 대한 Likelihood를 어떻게 계산하느냐에 따라서 pure Bayesian, naive Bayesian, semi-naive Bayesian으로 구분됨

- naive Bayesian 방식은 사람의 키, 머리크기, 허리둘레가 서로 상관관계가 없는 독립변수라는 가정하에 키의 확률분포, 머리크기의 확률분포, 허리둘레의 확률분포를 각각 구한 후 각각의 확률을 서로 곱하여 최종 결합확률을 계산하는 방식

- pure Bayesian 방식은 사람이 가질 수 있는 모든 (키,머리크기,허리둘레) 조합에 대하여 확률분포를 계산하는 방식(naive Bayesian은 각 변수마다 확률을 계산했다면, pure Bayesian은 변수의 조합 즉 3차원으로 확률을 계산함)

- naive Bayesian 방식은 feature간의 상관관계(키와 머리크기가 가지는 상관관계)를 무시하고 확률을 계산함(이래서 딥러닝에서 다중공선성을 중요하게 여기는 것이군...)

- 만약에 feature간의 상관관계가 없다면 naive Bayesian 방식으로 구한 확률 값도 맞는 값이 될 것이지만, 그렇지 않다면 pure Bayesian 방식으로 계산한 확률 값이 맞음, 그런데 pure Bayesian 방식은 계산하기 까다롭기 때문에 오차를 감수하더라도 naive Bayesian 방식으로 확률을 계산함

- semi-naive Bayesian은 feature들을 먼저 소그룹으로 그룹핑(grouping)을 한 후에 각 그룹 내에서는 feature들 간의 상관관계를 풀(full)로 계산하되, 그룹과 그룹 사이에서는 상관관계가 없는 것으로 확률을 계산하는 방식(만일 feature들을 실제 상관관계가 있는 것끼리 잘 그룹핑할 수만 있다면 semi-naive Bayesian 방식이 가장 효율적인 확률모델이 될 것)

## Maximum Likelihood Estimation(MLE)와 Maximum A Posterior(MAP)

- 관찰을 통해서도 Likelihood를 계산할 수 있지만, 단순히 정해지지 않은 몇 개의 parameter로 이루어진 함수로 모델링을 한 후에, 이 모델이 주어진 Data를 가장 잘 설명하도록 parameter들을 구해낼 수도 있고, 이 방법이 바로 딥러닝임

- MLE를 가우시안 분포로 가정하고 풀면 MSE와 동치

- MLE를 베르누이 분포로 가정하고 풀면 CE와 동치

- MLE는 Likelihood 함수의 최대값을 찾는 방범임

- Likelihood는 지금 얻은 데이터가 이 분포로부터 나왔을 가능도를 말함, 즉 Likelihood 함수는 각 데이터 샘플에서 현재 추정하고자 하는 분포에서 나올 가능도를 계산하여 이들을 모두 곱한 것임

- MLE를 사용하여 우리는 주어진 데이터를 가지고 Likelihood 함수를 최대값으로 만들 수 있는 파라미터를 얻고자 모델의 가중치를 업데이트 해나가며, 최적의 가중치를 찾아나감

- 일반적인 딥러닝에서 MLE의 Likelihood 함수는 가중치를 모르기 때문에, 가중치에 대한 함수값으로 표현이됨

- 사후확률은 데이터가 주어졌을 때의 가중치의 분포, 사전확률은 가중치에 대한 확률 값, Likelihood 함수는 가중치가 주어졌을 때의 데이터의 분포 값

- 각 샘플들의 Likelihood 값은 서로 독립적이기 때문에 Likelihood를 계산할 때 서로 곱하게됨, 그런데 곱하면 값이 너무 커지기 때문에 우리는 log를 취해줌으로써 덧셈으로 변경함

- Deep Learning 등에서 L2 Loss를 이용한다는 것은 주어진 Data로부터 얻은 Likelihood를 최대화시키겠다는 뜻으로 해석할 수 있음, 즉 L2 Loss를 최소화 시키는 일은 Likelihood를 최대화 시키는 일인 것

- MAP는 사후확률은 최대화 시키는 방법임

- 우리는 사후확률을 계산할 때 Likelihood와 사전 확률은 같이 사용함, 즉 MAP는 Likelihood와 사전 확률은 같이 사용하여 사후확률은 최대화함

- 딥러닝에서 MAP를 사용하는 것은 사전 확률이 결국 파라미터에 대한 확률값을 의미하기 때문에 Weight Decay(Regularization)라는 방식으로 사용됨

- L2 Regularization을 쓴다는 것은 주어진 Data를 적용함과 동시에 w에 Gaussian Distribution이라는 Prior를 걸어 주어 MAP를 통해 w를 구하겠다는 것으로 해석할 수 있음

- L1 Regularization을 쓴다는 것은 주어진 Data를 적용함과 동시에 w에 Laplacian Distribution이라는 Prior를 걸어 주어 MAP를 통해 w를 구하겠다는 것으로 해석할 수 있음

- 구하고자 하는 대상을 철저히 데이터만을 이용해서 구하고 싶다면 MLE를 이용하는 것

- 데이터와 더불어 우리가 갖고 있는 사전 지식까지 반영하고 싶다면 MAP를 이용하는 것(사전 지식에 어떻게 보면 output에 대한 특정 제약 조건이라고 볼 수 있음)

- 어떤 함수의 최대값을 찾는 방법 중 가장 보편적인 방법은 미분계수를 이용하는 것이고, 우리는 MAE, MAP의 식을 경사하강법을 이용하여 최대가 되는 가중치(모수)를 찾을 수 있음

- https://hyeongminlee.github.io/post/bnn003_vi/

## Entorpy외 정보 이론
- https://angeloyeo.github.io/2020/10/26/information_entropy.html
- https://icim.nims.re.kr/post/easyMath/550